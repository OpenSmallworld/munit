#% text_encoding = iso8859_1
_package sw

_pragma(classify_level=debug)
##
## Top level test_case class providing infrastructure for tests
## that require an application to be running.
##
## This class provides a framework for writing tests that
## require an database, but not an application, to be running
## by implementing the following behaviour:
##
## * set_up() 
##   * ensure that there is a database
##   * ensure that the database is writable 
##     * It creates an in-memory scratchpad in any
##       datasets (as specified by dataset_names) in which the test
##       will make any changes.  
## * tear_down() 
##   * Remove the scratchpad so the dataset reverts to its original state. 
##
## Subclasses of database_test should implement the following methods:
##
## * writable_dataset_names - This should return the names of any datasets that need to be writable. 
##
## database_test provides the following API methods:
##
## * dataset( ds_name ) - This returns the dataset identified by ds_name  
##
def_slotted_exemplar( :database_test,
        {
		{ :properties,   _unset }
	},
        { :test_case, :database_system_test_mixin } )
$


_pragma(classify_level=debug)
database_test.define_shared_variable(:database_path,
        ##
        ## The location of the cambridge_db to use.
        ##
        "cbgsun11:/swdev/databases/dev_ds_500/ds/ds_admin", :public)
$


_pragma(classify_level=debug)
database_test.define_shared_variable(:concurrency_mode,
        ##
        ## The concurrecny_mode used to reference the database. This
        ## may be :single_user or :multi_user. The default is :multi_user.
        ##
        :multi_user, :public)
$


_pragma(classify_level=debug)
## This shared variable indicates if a database was opened by
## this test.  If so, it is closed in the one_time_tear_down()
## method. 
database_test.define_shared_variable( :database_opened?, _false, :private )
$


_pragma(classify_level=debug)
## This shared constant indicates if the database should be
## closed.  If true, it is closed in the one_time_tear_down()
## method regardless whether it was opened by this test.
database_test.define_shared_variable( :force_close?, _true, :private )
$

database_test.method_table.resolve_conflicts( :test_case )
$

_pragma(classify_level=debug)
_method database_test.properties
	## 
	##

	>> .properties
	
_endmethod
$


_pragma(classify_level=debug, usage={subclassable})
_method database_test.writable_dataset_names
	## 
	## A vector containing the names of any datasets that need to
	## be writable.
	##
        >> {}
_endmethod 
$
_pragma(classify_level=debug, usage={subclassable})
## nslots when opening world for dataset clone
database_test.define_shared_variable(:clone_nslots, 1000, :public )
$
_pragma(classify_level=debug, usage={subclassable})
_method database_test.dataset_clones
	## Number of database clones on which test will run
	## concurrently alongside when running on main dataset followed
	## by boolean indicating whether clones should be writable
	## See also run_with_clones() API.
	>> 0, _false 
_endmethod
$
database_test.define_shared_variable(:clones, property_list.new(), :private)
$

_pragma(classify_level=debug, usage={subclassable})
_private _method database_test.dataset_clones?
	## 
	## 
	>> _self.dataset_clones > 0 _andif 
		_not _self.writable_dataset_names.empty? _andif
		_self.database_opened?
_endmethod
$
_pragma(classify_level=restricted,topic=unit_testing)
_private _method database_test.writable_dataset_clones?
	## 
	## 
	_return _self.dataset_clones? _andif (_allresults _self.dataset_clones)[2]
_endmethod
$

_pragma(classify_level=restricted,topic=unit_testing)
_private _method database_test.make_dataset_clones()
	## 
	##
	_dynamic !output!,!error!,!terminal!
	_if _not _self.dataset_clones?	_then _return _endif

	worlds<< simple_vector.new(_self.dataset_clones)
	_for i _over 1.upto(_self.dataset_clones)
	_loop
		worlds[i]<< ds_world.new(_self.clone_nslots)
	_endloop
	_for ds_name _over _self.writable_dataset_names.fast_elements()
	_loop
		write("Clonning ",_self.dataset_clones," times database: ",ds_name)
		_block
			# Suppress witterage when creating clone
			_handling information _with procedure 
			_handling warning _with procedure
			!error!<< !terminal!<< !output!<< internal_text_output_stream.new()
			
			_if (v<< _self.dataset(ds_name)) _is _unset _then _continue _endif
			_self.clones[ds_name]<< simple_vector.new(_self.dataset_clones)			
			_for i, a_world _over worlds.fast_keys_and_elements()
			_loop
				_self.clones[ds_name][i]<< clone<< gis_ds_view.new(:write, :searchpath, v.searchpath)
				_for f _over v.files.fast_elements()
				_loop
					clone.add_file(f.name, :world, a_world )
				_endloop
				clone.init_view()
				clone.goto_top_alternative()
			_endloop
		_endblock
	_endloop 
_endmethod
$

_pragma(classify_level=restricted,topic=unit_testing)
_private _method database_test.given_writable_dataset_clones()
	## 
	## 
	_if _not _self.writable_dataset_clones?	_then _return _endif
	# Create a scratchpad for each dataset clone to hold any changes
	_for ds_name _over _self.writable_dataset_names.fast_elements()
	_loop
		_if (clones << _self.clones[ds_name]) _is _unset _then _continue _endif 
		_for i,clone _over clones.fast_keys_and_elements()
		_loop
			clone.goto_top_alternative(:readonly)
			clone.create_scratchpad( write_string("memory::ds",i) )
		_endloop
	_endloop	
_endmethod
$
_pragma(classify_level=restricted,topic=unit_testing)
_private _method database_test.close_dataset_clones()
	## 
	##
	_if _not _self.writable_dataset_clones?	_then _return _endif
	_for ds_name _over _self.writable_dataset_names.fast_elements()
	_loop
		_if (clones << _self.clones[ds_name]) _is _unset _then _continue _endif 
		_for clone _over clones.fast_elements()
		_loop
			clone.rollback()
			clone.up()
		_endloop
	_endloop
_endmethod
$
_pragma(classify_level=restricted,topic=unit_testing)
_method database_test.run_with_clones(ds_name, meth_name, _gather parameters)
	## Runs method METH_NAME for DS_NAME and all its clones in parallel
	## The method METH_NAME is expected to have parameters view and PARAMETERS.
	## Method is run in parallel on the view DS_VIEW and its clones.
	_if _self.dataset_clones < 1 _orif
	    (clones<< _self.clones[ds_name]) _is _unset
	_then
		_return _self.perform(meth_name, _self.dataset(ds_name), _scatter parameters)
	_endif

	_local aq<< atomic_queue.new(_self.dataset_clones + 1)
	_local a_test<< _self 
	_local run_for_dataset<< _proc @run_for_dataset(view, meth_name, _gather parameters)
					 _import aq, a_test
					 _dynamic !current_dsview!
					 !current_dsview!<< view
					 _protect
						 a_test.perform(meth_name, view, _scatter parameters)
					 _protection
						 aq.put(1)
					 _endprotect
				 _endproc
	
	_local started<< 0
	_protect
		started+<< 1
		run_for_dataset.fork(_self.dataset(ds_name), meth_name, _scatter parameters)
		_for clone _over clones.fast_elements()
		_loop
			started+<< 1
			run_for_dataset.fork(clone, meth_name, _scatter parameters)
		_endloop
	_protection
		write("Waiting for ",started," tests ",meth_name," to finish.") 
		id << 0
		_if started > 0
		_then 
			_loop
				# waiting 30 - 60 sec max
				_if aq.get(60 * 1000 * (started - id/2) / started) _is _unset _then _leave _endif 
				id+<< 1
				_if id >= started _then _leave _endif 
			_endloop
		_endif
	_endprotect	
_endmethod
$


_pragma(classify_level=debug, usage={subclassable})
_method database_test.other_dataset_names
        ##
        ## The names of any datasets which aren't in the normal SOC (eg case)
        ##
        >> {}
_endmethod 
$

_pragma(classify_level=debug)
_method database_test.one_time_set_up()
	##
	## This gets called before first test in this test class and
	## ensures that the correct database is available. 
	## It also creates a scratchpad to hold any transient data.
        ##
        ## Subclass implemetations should always call _super.
	##
        _super.one_time_set_up()
        _self.check_correct_database_open()
	_self.make_dataset_clones()
_endmethod
$
_pragma(classify_level=debug)
_private _method database_test.discard_clones()
	## 
	## 
	_if _not _self.dataset_clones? _orif _self.clones.empty? _then _return _endif 
	worlds<< set.new()
	_for clone _over _self.clones.an_element().fast_elements()
	_loop
		worlds.add(clone.files.an_element().world)
	_endloop
	_for clones _over _self.clones.fast_elements()
	_loop
		_for clone _over clones.fast_elements()
		_loop
			clone.discard()
		_endloop
	_endloop
	_for a_world _over worlds.fast_elements()
	_loop
		a_world.close()
	_endloop
	_self.clones.empty()
_endmethod
$

_pragma(classify_level=debug)
_method database_test.one_time_tear_down()
	##
	## This gets called before first test in next test class and
	## ensures that the database opened in this test is discarded.
	##
        ## Subclass implemetations should always call _super.
	##
        _super.one_time_tear_down()
	_if _self.database_opened? _orif
	    _self.force_close?
	_then 
		_self.discard_clones()
		gis_program_manager.reinitialise()
	_endif
_endmethod
$

_pragma(classify_level=debug)
_method database_test.set_up()
	##
	## This gets called before each test and ensures that the
	## correct database is available. 
	## It also creates a scratchpad to hold any transient data.
        ##
        ## Subclass implemetations should always call _super.
	##
        _super.set_up()
	.properties << property_list.new()
	_self.given_writable_datasets( _self.writable_dataset_names )
	_self.given_writable_dataset_clones()
_endmethod
$
_pragma(classify_level=debug)
_method database_test.run_bare()
	## 
	## 
	#
	# The Cambridge DB exemplars are declared in the user package,
	# so this must be current when we open the database
	#
	_dynamic !current_package! << !current_package!.all_packages[:user]
	_super.run_bare()
_endmethod
$

_private _method database_test.check_correct_database_open()
        ## 
        ## If there is no database open, then opens the nominated
        ## one. If one is open but it isn't the correct one (the ace
        ## path is incorrect) then closes that and opens the correct
        ## one.
        ##
	
	_self.database_opened? << _false
	
        _if _not ds_environment.c_is_initialised? _orif
            gis_program_manager.ace_top_view _is _unset _orif
            gis_program_manager.ace_top_view.searchpath.at_using_default("", 1) <> _self.database_path _orif
            ds_environment.concurrency_mode <> _self.concurrency_mode
        _then 
                #
                # Suppress witterage. Note that
                # raw_swdp_manager.open_partition() forcibly witters to
                # !terminal! and that easily can't be suppressed without hiding
                # real errors. 
                #
                _handling information _with procedure 
                _handling warning _with procedure
                ds_environment.concurrency_mode << _self.concurrency_mode
                smallworld_product.set_startup_option(:authorisation, :singleuser)
                smallworld_product.set_startup_option(:login, "root")
                gis_program_manager.reinitialise()

                open_database({_self.database_path})
		_self.database_opened? << _true
        _endif
        _self.open_other_datasets()
_endmethod
$


_pragma(classify_level=debug)
_method database_test.tear_down()
	##
	## This gets called after each test and deletes the scratchpad.
	##

	_super( test_case ).tear_down()
	_self.close_datasets()
	_self.close_dataset_clones()
_endmethod
$

_pragma(classify_level=debug)
_method database_test.open_other_datasets()
        ##
        ## Open any datasets used by the case tool
        ##
        _for name _over _self.other_dataset_names.elements()
        _loop 
                _if gis_program_manager.databases[name] _is _unset
                _then gis_program_manager.open_datasets(name)
                _endif 
        _endloop 
_endmethod 
$
_pragma(classify_level=restricted,topic=MUnit)
_private _method database_test.wait_for_threads_to_finish( task_owner )
	##
	## Wait for all the tasks on TASK_OWNER to finish.
	##
	## Wait for 1 second and check if TASK_OWNER.thread_pool is
	## empty.
	##
	## Implementation taken from application_system_test_mixin.

	_loop
		_if task_owner.task_runner().thread_pool.empty? _then _leave _endif
		_thisthread.sleep( 1000 )
	_endloop 
	
_endmethod
$
