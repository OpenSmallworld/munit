#% text_encoding = iso8859_1
_package sw

def_mixin(:implementer_test_mixin)
$

_pragma(classify_level=debug, topic={MUnit})
implementer_test_mixin.define_shared_constant(
	##
	## A cache of replca views, keyed on main views.  The elements of this list
	## should be replicas of those views, but in an alternative NOT managed by
	## Design Manager
	##
	:replica_non_dm_views,
	equality_property_list.new(),
	_true
				)
$



_pragma(classify_level=debug, topic={MUnit})
implementer_test_mixin.define_shared_constant(
	##
	## A cache of replca views, keyed on main views.  The elements of this list
	## should be replicas of those views, but in an alternative managed by
	## Design Manager
	##
	:replica_dm_views,
	equality_property_list.new(),
	_true
				)
$

_pragma(classify_level=debug, topic={MUnit})
implementer_test_mixin.define_shared_constant(:disabled_implementer_tests,
	## Defines a set of implementer tests that are no longer valid
	## in the stream. This should be subclassed by individual
	## tests.
	##
	## Each entry is a property list of method/value pairs. If all
	## match the implementer, it is disabled. In general this
	## should include datamodel_name, sub_datamodel_name and
	## version.
	##
	## E.g. property_list.new_with(:datamodel_name, "eo_cs_config",
	##			       :sub_datamodel_name, "eo_ape",
	##			       :version, 2)
	{
	},
	:private)
$


_pragma(classify_level=debug, topic={MUnit})
_abstract _method implementer_test_mixin.implementer_module()
	##
	## Return the module for which the implementers should be
	## tested,
	## e.g. sw_module_manager.module(:co_datamodel_implementer)
	##

_endmethod
$	


_pragma(classify_level=debug, topic={MUnit}, usage={subclassable})
_private _method implementer_test_mixin.set_up_implementer(implementer)
	##
	## Set up any specific configuration for running the user and
	## case implementer tests defined on the given
	## datamodel_implementer.
	## 
	## This is intended for use on older implementer versions where
	## certain behaviour and/or data is not valid in the current
	## system. The standard test set_up() method should be used for
	## generic test behaviour.
	##

_endmethod
$

_pragma(classify_level=debug, topic={MUnit}, usage={subclassable})
_private _method implementer_test_mixin.tear_down_implementer(implementer)
	##
	## Discard any specific configuration for running the user and
	## case implementer tests defined on the given
	## datamodel_implementer.
	## 
	## This is intended for use on older implementer versions where
	## certain behaviour and/or data is not valid in the current
	## system. The standard test tear_down() method should be used
	## for generic test behaviour.
	##

_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
_method implementer_test_mixin.test_implementer()
	##
	## Run the post_test methods on the implementer
	##
	
	_local me << _self
	_block
		
                _handling implementer_warning _with _proc(warning)
							    _import me
							    me.assert_true(_false, warning.report_contents_string)
                _endproc
		
		
                _handling datamodel_test_failed _with _proc(warning)
							       _import me
							       me.assert_true(_false, warning.report_contents_string)
                _endproc

		gis_program_manager.ace_view.commit()
		implementer_module << _self.implementer_module()

		_if implementer_module _isnt _unset
		_then
			
			_for implementer _over _self.datamodel_implementers_to_test(implementer_module)
			_loop
				_self.int!test_implementer(implementer)
			_endloop

		_endif
			
	_endblock
	
_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
_private _method implementer_test_mixin.int!test_implementer(implementer)
	##
	## Run the post_test methods for a single implementer IMPLEMENTER
	##
	
	_self.set_up_implementer(implementer)

	(user_views, case_views) << _self.views_for(implementer)
	
	_if (case_test_method << implementer.properties[:case_post_test_method]) _isnt _unset
	_then
		_self.int!test_implementer_on_views(implementer, case_views, case_test_method)
	_endif

	_if (user_test_method << implementer.properties[:user_post_test_method]) _isnt _unset
	_then
		_self.int!test_implementer_on_views(implementer, user_views, user_test_method)
	_endif	
	
	_self.tear_down_implementer(implementer)
_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
_private _method implementer_test_mixin.int!test_implementer_on_views(implementer, views, test_method)
	##
	## Assert that there's at least one view and then
	## run TEST_METHOD on IMPLEMENTER for each view in VIEWS.
	##
	
	_local me << _self
	_block
		_handling implementer_warning _with _proc(warning)
							    _import me, implementer, test_method
							    contents << warning.report_contents_string
							    me.assert_true(_false, write_string(implementer, newline_char,
												me.class_name, %.,
												test_method, newline_char,
												contents))
		_endproc
		
		
		_handling datamodel_test_failed _with _proc(warning)
							      _import me, implementer, test_method
							      contents << warning.report_contents_string
							      me.assert_true(_false, write_string(implementer, newline_char, 
												  me.class_name, %.,
												  test_method, newline_char,
												  contents))
		_endproc
		
		_self.assert_false(views.empty?)
		_for view _over views.fast_elements()
		_loop
			write("Testing ", implementer, " in ", view, " ", view.alternative_path_name())
			implementer.perform(test_method, view)
		_endloop
	_endblock
	
_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
_private _method implementer_test_mixin.can_test_implementer?(implementer)
	## Returns true if the given implementer is still valid to
	## test.
	##
	## Disabled implementers are as defined by
	## self.disabled_implementer_tests

	_for data _over _self.disabled_implementer_tests.fast_elements()
	_loop @outer
		_for k, e _over data.fast_keys_and_elements()
		_loop
			_if k.send_to(implementer) ~= e
			_then
				_continue @outer
			_endif
		_endloop

		# Found a match so can't run this
		_return _false
	_endloop

	# datamodel_prerequisite objects can't be tested
	_if implementer.prerequisite?
	_then
		_return _false
	_endif

	_return _true
_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
_iter _method implementer_test_mixin.datamodel_implementers_to_test(implementer_module)
	## 
	## Return the implementers to test
	##
	## This is all the datamodel implementers for
	## IMPLEMENTER_MODULE
	##

	_for implementer _over implementer_module.datamodel_implementers().fast_elements()
	_loop
		_if _self.can_test_implementer?(implementer)
		_then
			_loopbody(implementer)
		_endif
	_endloop
_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
implementer_test_mixin.define_shared_constant(
	:get_replica_view_in_design_alt_for_tests?,
	_false,
	_true
		       )
$

_pragma(classify_level=debug, topic={MUnit})
implementer_test_mixin.define_shared_constant(
	:get_replica_view_in_non_design_alt_for_tests?,
	_false,
	_true
		       )
$

_pragma(classify_level=debug, topic={MUnit})
_method implementer_test_mixin.views_for(implementer)
	##
	## Returns two ropes of views for IMPLEMENTER.
	## The first rope contains target user views, the second
	## contains target case views.
	## Depending on the values of get_replica_view_in_design_alt_for_tests? &
	## get_replica_view_in_non_design_alt_for_tests? then replicas of the main view
	## may be returned in different alternatives
	##
	
	user_views << rope.new()
	case_views << rope.new()
	_for target_view _over implementer.target_views().fast_keys()
	_loop
		_if  target_view.targets_user_view? _is _true
		_then
			view << target_view.target_user_view()
			user_views.add(view)
			_if view.alternative_level > 0
			_then
				view.goto_top_alternative()
			_endif
			
			_if _self.get_replica_view_in_design_alt_for_tests? _andif
			    (rv << _self.get_replica_view_in_alternative( view, _true )) _isnt _unset
			_then
				user_views.add(rv)
			_endif
			
			_if _self.get_replica_view_in_non_design_alt_for_tests? _andif
			    (rv << _self.get_replica_view_in_alternative( view, _false )) _isnt _unset
			_then
				user_views.add(rv)
			_endif
			
		_endif
		_if  target_view.targets_case_view? _is _true
		_then
			view << target_view.target_case_view()
			case_views.add(view)
		_endif
	_endloop
	_return user_views, case_views
_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
_method implementer_test_mixin.target_views_proc(_optional case_view_name, user_view_name)
	## 
	## Return a procedure that stubs the target_views() method to
	## only return the electric dataset.
	##

	target_views_proc << _proc()
				     _import case_view_name, user_view_name
				     user_view << gis_program_manager.cached_dataset(user_view_name.default(:electric))
				     case_view << gis_program_manager.cached_dataset(case_view_name.default(:electric_case))
				     implementer_view << pseudo_slotted_list.new_with(:|target_user_view()|,
										      user_view,
										      :|target_case_view()|,
										      case_view,
										      :targets_user_view?,
										      _true,
										      :targets_case_view?,
										      _true)
				     >> property_list.new_with(implementer_view, implementer_view)
			     _endproc

	>> target_views_proc
	
_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
_private _method implementer_test_mixin.get_replica_view_in_alternative( a_view, design_alt? )
	##
	## Return a replica of A_VIEW
	## If DESIGN_ALT? is true then attempts to return the replica with it in an
	## alternative that is part of a design
	## If DESIGN_ALT? is false then attempts to return the replica with it in an
	## alternative that is NOT part of a design
	## Will return unset if a suitable alternative is not found
	##
	replicas << _if design_alt?
		    _then
			    >> _self.replica_dm_views
		    _else
			    >> _self.replica_non_dm_views
		    _endif
	
	_if (rv << replicas[a_view]) _is _unset
	_then
		rv << a_view.replicate()
		replicas[a_view] << rv
	_endif

	
	dm_top_path << swg_dsn_user_alternative_control.design_top_alternative_path(a_view.name)

	_if design_alt?
	_then
		_if dm_top_path _is _unset
		_then
			write("No dm top configured for ", a_view)
			_return _unset 
		_endif
		
		#First, drop down to DM Top
		rv.go_to_alternative(dm_top_path)
	_else
		rv.goto_top_alternative()
	_endif
	
	_for alt _over rv.alternatives.elements()
	_loop
		alt_name << alt.alternative_name
		#Ignore DM Top
		_if alt_name <> dm_top_path
		_then
			_leave
		_endif
	_endloop

	>> _if alt_name _isnt _unset
	   _then
		   rv.down(alt_name)
		   >> rv
	   _else
		   >> _unset
	   _endif
_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
_private _method implementer_test_mixin.define_test_method( method_name, implementer, test_method, views )
	##
	## Defines a new method, named METHOD_NAME on _self.  This method will loop
	## over VIEWS, passing them into calls to IMPLEMENTER.TEST_METHOD.
	## Any implementer_warning or datamodel_test_failed warnings conditions will be
	## caught and presented as munit failures, including the original condition's
	## report string.
	##
	_local me << _self
	_local imp_warning_handler <<
		_proc(warning)
			_import me
			me.assert_true(
				_false,
				warning.report_contents_string)
		_endproc
	_local imp_failure_handler <<
		_proc(warning)
			_import me
			me.assert_true(_false, warning.report_contents_string)
		_endproc
	test_proc << _proc()
			     _import test_method
			     _import implementer
			     _import views
			     _import imp_warning_handler
			     _import imp_failure_handler

			     _block 
				     _handling implementer_warning _with imp_warning_handler		     
				     _handling datamodel_test_failed _with imp_failure_handler
				     
				     _for i_view _over views.elements()
				     _loop
					     write("Performing ", implementer, %., test_method,
						   "() on ", i_view)
					     implementer.perform(test_method, i_view)
				     _endloop
			     _endblock 
		     _endproc
	>> _self.define_method(method_name.as_symbol(), test_proc, _false)
_endmethod
$

_pragma(classify_level=debug, topic={MUnit})
_method implementer_test_mixin.define_individual_test_methods()
	##
	## Overrides the test_implementer() method and defines new methods for each of
	## the implementers associated with self so that the result of each test is
	## reported separately.
	## If an implementer has a case_post_test_method defined then this will be the
	## basis of a test method named test_case_method!<case_post_test_method>, which will
	## perform that method passing in each case view configured for the implementer.
	## The same is repeated for any defined user_post_test_methods.
	##
	_self.define_method(:|test_implementer()|,
			    _proc()
				    write(_self, ".test_implementer() has been replaced with individual test methods")
			    _endproc,
			    _false
			    )
	
	_if (implementer_module << _self.implementer_module()) _isnt _unset
	_then	
		_for implementer _over _self.datamodel_implementers_to_test(implementer_module)
		_loop
			(user_views, case_views) << _self.views_for(implementer)
			_if (case_test_method << implementer.properties[:case_post_test_method]) _isnt _unset
			_then
				#write("case test method: ", case_test_method, "  ", implementer)
				_self.define_test_method(
					write_string("test_case_method!", case_test_method),
					implementer,
					case_test_method,
					case_views
					)
			
			_endif
			
			_if (user_test_method << implementer.properties[:user_post_test_method]) _isnt _unset
			_then
				_self.define_test_method(
					write_string("test_user_method!", user_test_method),
					implementer,
					user_test_method,
					user_views
					)
			_endif
			
		_endloop
	_endif
_endmethod
$
